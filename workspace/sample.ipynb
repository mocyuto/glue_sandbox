{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d2bd6ad-024c-445a-8fde-3084e870fb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import boto3\n",
    "from awsglue.utils import getResolvedOptions\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.job import Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8abeb2d9-3427-43b0-abb8-a706978bd198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.executor.extraClassPath', '/opt/aws-glue-libs/jarsv1/*'),\n",
       " ('spark.sql.warehouse.dir', 'file:/opt/jupyter/workspace/spark-warehouse'),\n",
       " ('spark.driver.extraClassPath', '/opt/aws-glue-libs/jarsv1/*'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.app.name', 'PySparkShell'),\n",
       " ('spark.driver.port', '35365'),\n",
       " ('spark.app.startTime', '1634485674146'),\n",
       " ('spark.sql.catalogImplementation', 'hive'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.driver.host', 'ac4f70216706'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.master', 'local[*]'),\n",
       " ('spark.submit.pyFiles', ''),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.ui.showConsoleProgress', 'true'),\n",
       " ('spark.app.id', 'local-1634485675752')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.argv += ['--JOB_NAME', 'glue_script']\n",
    "args = getResolvedOptions(sys.argv, ['JOB_NAME'])\n",
    "\n",
    "spark = SparkSession.builder.config('spark.serializer','org.apache.spark.serializer.KryoSerializer').getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "glueContext = GlueContext(sc)\n",
    "job = Job(glueContext)\n",
    "job.init(args['JOB_NAME'], args)\n",
    "sc.getConf().getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f362d19-a4dd-4a10-85f4-57d60641636d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TEST_S3_ENDPOINT_URL\"] = \"http://glue.dev.s3.local:4566\"\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.endpoint\", \"http://glue.dev.s3.local:4566\")\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.path.style.access\", \"true\")\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.signing-algorithm\", \"S3SignerType\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0886a4e0-6c58-4e77-9f5e-911cf6f14d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.session.Session(\n",
    "    aws_access_key_id = 'xxx',\n",
    "    aws_secret_access_key = 'xxx'\n",
    ")\n",
    "s3client = session.client(\n",
    "    \"s3\",\n",
    "    endpoint_url=os.environ[\"TEST_S3_ENDPOINT_URL\"],\n",
    "    use_ssl=False,\n",
    ")\n",
    "bucket = s3client.create_bucket(Bucket = 'test-bucket')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8851ee2d-cc3d-4f56-9911-972970d6e813",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource(\n",
    "    \"s3\",\n",
    "    endpoint_url=os.environ[\"TEST_S3_ENDPOINT_URL\"],\n",
    "    region_name=\"ap-northeast-1\",\n",
    "    use_ssl=False,\n",
    "   \n",
    ")\n",
    "bucket_name = \"test-bucket\"\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "bucket.upload_file(\"test_data/sample.json\", \"sample/sample.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cf250c4-e31b-4ca1-960e-bd1a142a81d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|  name|\n",
      "+------+\n",
      "|  taro|\n",
      "|  jiro|\n",
      "|saburo|\n",
      "| shiro|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p = f\"s3://{bucket_name}/sample/sample.json\"\n",
    "df = glueContext.create_dynamic_frame.from_options(\n",
    "    connection_type=\"s3\",\n",
    "    connection_options={\"paths\": [p]},\n",
    "    format=\"json\"\n",
    ").toDF()\n",
    "df.count()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d239267-b3bb-41bc-9327-4f0f16151737",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ANTLR Tool version 4.8 used for code generation does not match the current runtime version 4.7.2ANTLR Runtime version 4.8 used for parser compilation does not match the current runtime version 4.7.2ANTLR Tool version 4.8 used for code generation does not match the current runtime version 4.7.2ANTLR Runtime version 4.8 used for parser compilation does not match the current runtime version 4.7.221/10/17 15:58:30 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "21/10/17 15:58:30 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "21/10/17 15:58:39 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0\n",
      "21/10/17 15:58:39 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@192.168.32.3\n",
      "21/10/17 15:58:39 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException\n",
      "21/10/17 15:58:39 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-----------+\n",
      "|database|tableName|isTemporary|\n",
      "+--------+---------+-----------+\n",
      "|        |   sample|       true|\n",
      "+--------+---------+-----------+\n",
      "\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       4|\n",
      "+--------+\n",
      "\n",
      "+------+\n",
      "|  name|\n",
      "+------+\n",
      "|  taro|\n",
      "|  jiro|\n",
      "|saburo|\n",
      "| shiro|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"sample\")\n",
    "spark.sql(\"show tables\").show()\n",
    "spark.sql(\"select count(*) from sample\").show()\n",
    "spark.sql(\"select * from sample\").show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
